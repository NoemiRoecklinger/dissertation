{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is my file to create all features for the ML process\n",
    "\n",
    "I have my cleaned file with revised classes (1-11): Dataset_for_ML \n",
    "\n",
    "Now I take that and calculate all the other features for it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import sklearn \n",
    "import scipy.linalg as scplinag\n",
    "from sklearn.neighbors import KDTree\n",
    "import time\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcCovarianceMatrix(data):\n",
    "    \"\"\"\n",
    "    Function to compute the covariance matrix.\n",
    "    \n",
    "    Input: Dataset of 3D points; i.e. array of dimension: #points x 3 \n",
    "    Output: 3x3 covariance matrix (np.array)\n",
    "    \"\"\"\n",
    "    # Create covariance matrix and array to store the mean values for x_mean, y_mean, z_mean\n",
    "    C = np.zeros((data.shape[1], data.shape[1]))\n",
    "    mean_xyz = []\n",
    "    # Calculate all mean values\n",
    "    for i in range(0, data.shape[1]):\n",
    "        mean_xyz.append(data[:,i].mean())\n",
    "    mean_xyz = np.array(mean_xyz)\n",
    "    # Check whether dimensions agree \n",
    "    if data[:,0].size != data[:,1].size or data[:,0].size != data[:,2].size:\n",
    "        print \"X, Y and Z must be of same dimensions.\"\n",
    "    else:\n",
    "        # For each row in covariance matrix C\n",
    "        for i in range(0, C.shape[0]):\n",
    "            # For each column in covariance matrix C\n",
    "            for j in range(0, C.shape[1]):\n",
    "                C[i,j] = 0\n",
    "                # For each point in the dataset, access x, y, z-values\n",
    "                for point in data:\n",
    "                    # For each point, access x,y and z in all combinations (xx, xy, xz, yx, yy, yz etc)\n",
    "                    C[i][j] = C[i][j] + (point[i]-mean_xyz[i])*(point[j]-mean_xyz[j])\n",
    "    # Divide by the total number of points                \n",
    "    C = (1.0/data.shape[0]) * C\n",
    "    return C "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get eight parameters for each point\n",
    "\n",
    "def calcFeatureDescr(covarianceMatrix):\n",
    "    \"\"\"\n",
    "    Function to compute the 8 feature descriptors for each point.\n",
    "    \n",
    "    Input: 3x3 Covariance matrix of a point and its neighbourhood \n",
    "    \n",
    "    Output: np Array with feature descriptors as described by Weinmann et al. (1D array with 8 elements)\n",
    "    \n",
    "    \"\"\"\n",
    "    D, V = scplinag.eig(covarianceMatrix)\n",
    "    # We sort the array with eigenvalues by size (from smallest to largest value)\n",
    "    D.sort()\n",
    "    # Get eigenvectors\n",
    "    e1 = V[2] # eigenvector in direction of largest variance\n",
    "    e2 = V[1] # second eigenvector, perpend. to e1\n",
    "    e3 = V[0]\n",
    "    # Find the eigenvalues\n",
    "    evalue1 = D[2] # largest\n",
    "    evalue2 = D[1]\n",
    "    evalue3 = D[0] # smallest\n",
    "\n",
    "    # Linearity\n",
    "    lambda1 = (evalue1 - evalue2) / evalue1\n",
    "    # Planarity\n",
    "    lambda2 = (evalue2 - evalue3) / evalue1\n",
    "    # Scattering\n",
    "    lambda3 = evalue3 / evalue1\n",
    "    # Omnivariance\n",
    "    misc1 = np.prod(D)\n",
    "    lambda4 = pow(misc1,(1.0/3))\n",
    "    # Anisotropy\n",
    "    lambda5 = (evalue1 - evalue3) / evalue1\n",
    "    # Eigentropy\n",
    "    s = 0\n",
    "    count = 0\n",
    "    for elem in D:\n",
    "        if elem == 0:\n",
    "            s = 0\n",
    "            count = 1\n",
    "        else:\n",
    "            # Only if bigger than 0\n",
    "            misc2 = (elem*np.log(elem))\n",
    "            if misc2 == 0:\n",
    "                print \"Multiplication result too close to zero.\"\n",
    "                s = 0\n",
    "            else:\n",
    "                s = s + misc2\n",
    "    lambda6 = (-1)*s  \n",
    "    # Sum of eigenvalues\n",
    "    lambda7 = sum(D)\n",
    "    # Change of curvature\n",
    "    lambda8 = evalue3/sum(D)\n",
    "    \n",
    "    featureDescriptor = np.array([lambda1, lambda2, lambda3, lambda4, lambda5, lambda6, lambda7, lambda8])\n",
    "    return featureDescriptor, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get local point density\n",
    "\n",
    "def calcPointDensity(number_NN, radius):\n",
    "    \"\"\"\n",
    "    Function to compute the local point density as introduced by Weinmann 2013 (Formula 2).\n",
    "    \n",
    "    Input: number of NN (scalar), calculated radius (scalar) of the neighbourhood determined\n",
    "            by the number of points. Ideally, this should have a small STD as density is not varying too\n",
    "            much after cleaning the dataset \n",
    "    \n",
    "    Output: Local point density (scalar)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    D = (number_NN+1.0)/((4.0/3)*np.pi*pow(radius, 3))\n",
    "    \n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a data frame with all my data# Define  \n",
    "FILE_PATH = r\"../DATA\"\n",
    "FILE_NAME = r\"/Dataset_for_ML_verticality.txt\"\n",
    "IMAGE_FILE_PATH = r\"images\"\n",
    "df = pd.read_csv(FILE_PATH+FILE_NAME, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5     6359799\n",
       "2     3230632\n",
       "3      884203\n",
       "13     318893\n",
       "14     105205\n",
       "4       59854\n",
       "12      39803\n",
       "11      23070\n",
       "7       18024\n",
       "15       8969\n",
       "6        3842\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to NumPy array \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 11052294\n",
      "Number of columns 6\n"
     ]
    }
   ],
   "source": [
    "# Data is the whole dataset but as a numpy array \n",
    "data = df.values\n",
    "rows, columns = data.shape\n",
    "print \"Number of rows:\", rows\n",
    "print \"Number of columns\", columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get only XYZ values\n",
    "dataxyz = data[:,0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute all features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created tree in: 1.22348467509e-05 minutes\n",
      "Queried tree in: 3.34024429321e-05 minutes\n",
      "This is the shape of the file: (100, 11)\n",
      "Computed features in: 0.00261881748835 minutes\n",
      "This is how many elements (eigenvalues) are 0 0\n"
     ]
    }
   ],
   "source": [
    "NN = 10\n",
    "# For all points now \n",
    "start = time.time()\n",
    "# Create kd-tree\n",
    "kdt = KDTree(dataxyz, leaf_size=40, metric='euclidean')\n",
    "print 'Created tree in:', float(time.time()-start)/60, 'minutes'\n",
    "# Get list with indices, the first value is always the point itself\n",
    "start = time.time()\n",
    "idx_list = kdt.query(dataxyz, k=NN, return_distance=False, sort_results = True)\n",
    "print 'Queried tree in:', float(time.time()-start)/60, 'minutes'\n",
    "start = time.time()\n",
    "store = []\n",
    "radii = []\n",
    "point_density = []\n",
    "counter = []\n",
    "for j in range(0, dataxyz.shape[0]):\n",
    "    # Look at all points now\n",
    "    neighbourhood = []\n",
    "    for i in idx_list[j]:\n",
    "        neighbourhood.append(dataxyz[i])\n",
    "    neighbourhood = np.array(neighbourhood)\n",
    "    # Calculate radius for neighbourhood\n",
    "    idx_first_point = idx_list[j][0]\n",
    "    idx_last_point = idx_list[j][-1]\n",
    "    first_point = dataxyz[idx_first_point]\n",
    "    last_point = dataxyz[idx_last_point]\n",
    "    radius_neighbourhood = distance.euclidean(first_point, last_point)\n",
    "    radii.append(radius_neighbourhood)\n",
    "    # Point density \n",
    "    D = calcPointDensity(NN, radius_neighbourhood)\n",
    "    point_density.append(D)\n",
    "    # Everything we did before with dataset, we do now with the neighbourhood only\n",
    "    C = calcCovarianceMatrix(neighbourhood)\n",
    "    feat, count = calcFeatureDescr(C)\n",
    "    counter.append(count)\n",
    "    row_with_additional_col = np.append(dataxyz[j], feat)\n",
    "    store.append(row_with_additional_col)\n",
    "store_complex = np.array(store)\n",
    "store = np.real(store_complex)\n",
    "print \"This is the shape of the file:\", store.shape\n",
    "print 'Computed features in:', float(time.time()-start)/60, 'minutes'\n",
    "c = 0\n",
    "for elem in counter:\n",
    "    if elem == 1:\n",
    "        c = c + 1\n",
    "print \"This is how many elements (eigenvalues) are 0:\", c\n",
    "\n",
    "# Create a data frame with the calculated features \n",
    "df2 = pd.DataFrame({\n",
    "    'X': store[:,0],\n",
    "    'Y': store[:,1],\n",
    "    'Z': store[:,2],\n",
    "    'relative_height': df['relative_height'],\n",
    "    'verticality': df['verticality'],\n",
    "    'lambda1': store[:,3],\n",
    "    'lambda2': store[:,4],\n",
    "    'lambda3': store[:,5],\n",
    "    'lambda4': store[:,6],\n",
    "    'lambda5': store[:,7],\n",
    "    'lambda6': store[:,8],\n",
    "    'lambda7': store[:,9],\n",
    "    'lambda8': store[:,10],\n",
    "    'radius_neighbourhood': radii,\n",
    "    'local_density': point_density,\n",
    "    'class': df['class']\n",
    "})\n",
    "df2.to_csv(FILE_PATH+'/5_Data_ML_attributes_10NN.txt', index= False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
