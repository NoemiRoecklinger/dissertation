{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this file over night on Daves computer\n",
    "# Date: 11/7/2018\n",
    "\n",
    "# Aim: for each point in the dataset, compute the feature descriptor (for now: with k=10 neighbours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import sklearn \n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.linalg as scplinag\n",
    "from sklearn.neighbors import KDTree\n",
    "import functionsCollection as fnct # This is my collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../DATA/Cassette_GT.txt', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "\n",
    "# Get rid of NAN line on top\n",
    "df = df.drop([0])  \n",
    "# Rename the column \n",
    "df = df.rename(index=str, columns={\"//X\": \"X\"})\n",
    "# Get rid of id column \n",
    "df = df.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data is now a numpy ndarray with 1048575 rows and 4 cols \n",
    "data = df.values\n",
    "data.shape\n",
    "# This is the dataset in xyz only \n",
    "dataxyz = data[:,0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create kd-tree\n",
    "# This takes the longest time now and it is very computationally expensive \n",
    "kdt = KDTree(dataxyz, leaf_size=30, metric='euclidean')\n",
    "# Get list with indices, the first value is always the point itself\n",
    "idx_list = kdt.query(dataxyz, k=100, return_distance=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = []\n",
    "for j in range(0, dataxyz.shape[0]):\n",
    "    # Look at all points now\n",
    "    neighbourhood = []\n",
    "    for i in idx_list[j]:\n",
    "        neighbourhood.append(dataxyz[i])\n",
    "    neighbourhood = np.array(neighbourhood)\n",
    "    # Everything we did before with dataset, we do now with the neighbourhood only\n",
    "    C = fnct.calcCovarianceMatrix(neighbourhood)\n",
    "    feat = fnct.calcFeatureDescr(C)\n",
    "    row_with_additional_col = np.append(dataxyz[j], feat)\n",
    "    store.append(row_with_additional_col)\n",
    "store = np.array(store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two files to work with later\n",
    "\n",
    "# Create a data frame with the calculated features \n",
    "df2 = pd.DataFrame({\n",
    "    'X': store[:,0],\n",
    "    'Y': store[:,1],\n",
    "    'Z': store[:,2],\n",
    "    'lambda1': store[:,3],\n",
    "    'lambda2': store[:,4],\n",
    "    'lambda3': store[:,5],\n",
    "    'lambda4': store[:,6],\n",
    "    'lambda5': store[:,7],\n",
    "    'lambda6': store[:,8],\n",
    "    'lambda7': store[:,9],\n",
    "    'lambda8': store[:,10]\n",
    "})\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
