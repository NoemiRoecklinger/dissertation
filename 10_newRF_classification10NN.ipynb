{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New classification\n",
    "\n",
    "This is my final classifications, with th optimised RF I determined before\n",
    "\n",
    "Now, I will only use td = 12 and 100 trees "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn \n",
    "from sklearn.neighbors import KDTree\n",
    "import time\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN = 10 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try first with the initial dataset, i.e. only the geometric features and following Weinmann 2014 \n",
    "\n",
    "No reflectance and no multi-scale features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uploadng my datasets\n",
    "# Define a data frame with all my data  \n",
    "FILE_PATH = r\"../DATA/ML_datasets/Initial_setup\"\n",
    "META_FILE_PATH = \"../DATA/META\"\n",
    "IMAGE_FILE_PATH = r\"images\"\n",
    "\n",
    "# Training data\n",
    "# use the sub-sampled dataset with only 3000 instances\n",
    "y_train = np.loadtxt(FILE_PATH+'/y_train_'+ str(NN) +'NN_3842samples.txt', delimiter=',')\n",
    "X_train = np.loadtxt(FILE_PATH+'/X_train_'+ str(NN) +'NN_3842samples.txt', delimiter=',')\n",
    "\n",
    "# Testing data\n",
    "y_test = np.loadtxt(FILE_PATH+'/y_test_'+ str(NN) +'NN.txt', delimiter=',')\n",
    "X_test = np.loadtxt(FILE_PATH+'/X_test_'+ str(NN) +'NN.txt', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=12, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=12, random_state=42, n_estimators=100, criterion='gini')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for the unseen dataset \n",
    "predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.8839393939393939\n",
      "Test score 0.7830007251887504\n"
     ]
    }
   ],
   "source": [
    "# This is my overall accuracy again \n",
    "score_train = clf.score(X_train, y_train)\n",
    "score_test = clf.score(X_test, y_test)\n",
    "\n",
    "print \"Train score:\", score_train*100\n",
    "print \"Test score\", score_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 0.8470836917064133\n",
      "recall 0.7830007251887504\n",
      "precision 0.9537797357383355\n"
     ]
    }
   ],
   "source": [
    "# Now precision, recall and F1 score\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "\n",
    "f1 = f1_score(y_test, predictions, average=\"weighted\")\n",
    "rec = recall_score(y_test, predictions, average=\"weighted\")\n",
    "prec = precision_score(y_test, predictions, average=\"weighted\")\n",
    "\n",
    "print \"F1\", f1\n",
    "print \"recall\", rec\n",
    "print \"precision\", prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 88.39393939393939\n",
      "Test score 78.30007251887504\n"
     ]
    }
   ],
   "source": [
    "print \"Train score:\", score_train*100\n",
    "print \"Test score\", score_test*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
