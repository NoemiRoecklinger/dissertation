{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New classification\n",
    "\n",
    "This is my final classifications, with th optimised RF I determined before\n",
    "\n",
    "Now, I will only use td = 12 and 100 trees "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn \n",
    "from sklearn.neighbors import KDTree\n",
    "import time\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN = 100 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try first with the initial dataset, i.e. only the geometric features and following Weinmann 2014 \n",
    "\n",
    "No reflectance and no multi-scale features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uploadng my datasets\n",
    "# Define a data frame with all my data  \n",
    "FILE_PATH = r\"../DATA/ML_datasets/Initial_setup\"\n",
    "META_FILE_PATH = \"../DATA/META\"\n",
    "IMAGE_FILE_PATH = r\"images\"\n",
    "\n",
    "# Training data\n",
    "# use the sub-sampled dataset with only 3000 instances\n",
    "y_train = np.loadtxt(FILE_PATH+'/y_train_'+ str(NN) +'NN_3842samples.txt', delimiter=',')\n",
    "X_train = np.loadtxt(FILE_PATH+'/X_train_'+ str(NN) +'NN_3842samples.txt', delimiter=',')\n",
    "\n",
    "# Testing data\n",
    "y_test = np.loadtxt(FILE_PATH+'/y_test_'+ str(NN) +'NN.txt', delimiter=',')\n",
    "X_test = np.loadtxt(FILE_PATH+'/X_test_'+ str(NN) +'NN.txt', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=12, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=12, random_state=42, n_estimators=100, criterion='gini')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for the unseen dataset \n",
    "predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.8996666666666666\n",
      "Test score 0.8416681784190523\n"
     ]
    }
   ],
   "source": [
    "# This is my overall accuracy again \n",
    "score_train = clf.score(X_train, y_train)\n",
    "score_test = clf.score(X_test, y_test)\n",
    "\n",
    "print \"Train score:\", score_train\n",
    "print \"Test score\", score_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 0.880286312360368\n",
      "recall 0.8416681784190523\n",
      "precision 0.9433058449323738\n"
     ]
    }
   ],
   "source": [
    "# Now precision, recall and F1 score\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "\n",
    "f1 = f1_score(y_test, predictions, average=\"weighted\")\n",
    "rec = recall_score(y_test, predictions, average=\"weighted\")\n",
    "prec = precision_score(y_test, predictions, average=\"weighted\")\n",
    "\n",
    "print \"F1\", f1\n",
    "print \"recall\", rec\n",
    "print \"precision\", prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 89.96666666666667\n",
      "Test score 84.16681784190523\n"
     ]
    }
   ],
   "source": [
    "print \"Train score:\", score_train*100\n",
    "print \"Test score\", score_test*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Road       0.99      0.91      0.95    646126\n",
      "       Sidewalk       0.78      0.88      0.82    176841\n",
      "           Curb       0.31      0.99      0.47     11971\n",
      "       Building       1.00      0.81      0.89   1271960\n",
      "Other pole-like       0.03      0.96      0.05       768\n",
      "    Small poles       0.70      0.98      0.82      3605\n",
      "    Pedestrians       0.04      0.74      0.08      4614\n",
      "     2-wheelers       0.13      0.74      0.22      7960\n",
      "     4-wheelers       0.41      0.68      0.51     63779\n",
      "          trees       0.26      0.95      0.40     21041\n",
      "  Potted plants       0.14      0.81      0.23      1794\n",
      "\n",
      "    avg / total       0.94      0.84      0.88   2210459\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['Road', 'Sidewalk', 'Curb', 'Building', 'Other pole-like', \n",
    "                'Small poles', 'Pedestrians', '2-wheelers', '4-wheelers','trees', 'Potted plants']\n",
    "print classification_report(y_test, predictions, target_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix  = confusion_matrix(y_test, predictions)\n",
    "\n",
    "np.savetxt(FILE_PATH + \"/confusionMatrix_scenarioA3_100NN.txt\", conf_matrix, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
